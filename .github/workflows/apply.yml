name: Deploy Vertica DB (apply)

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      recreate:
        description: Destroy the existing stack before applying
        required: false
        type: boolean

concurrency:
  group: vertica-db-apply
  cancel-in-progress: false

jobs:
  preflight:
    runs-on: ubuntu-latest
    outputs:
      ready: ${{ steps.check.outputs.ready }}
    steps:
      - name: Check required AWS secrets
        id: check
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
        run: |
          set -euo pipefail
          missing=()
          for name in AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_REGION AWS_ACCOUNT_ID; do
            if [ -z "${!name:-}" ]; then
              missing+=("$name")
            fi
          done

          if [ ${#missing[@]} -eq 0 ]; then
            echo "ready=true" >> "$GITHUB_OUTPUT"
            {
              echo "### ✅ Vertica apply prerequisites"
              echo
              echo "All required AWS secrets are configured."
            } >> "$GITHUB_STEP_SUMMARY"
          else
            {
              echo "### ⚠️ Vertica apply prerequisites missing"
              echo
              echo "The deploy job was skipped because these secrets are unset:"
              for name in "${missing[@]}"; do
                echo "- \`$name\`"
              done
              echo
              echo "Set them under **Settings → Secrets and variables → Actions** to enable automatic deploys."
            } >> "$GITHUB_STEP_SUMMARY"
            echo "ready=false" >> "$GITHUB_OUTPUT"
          fi

  apply:
    needs: preflight
    if: ${{ needs.preflight.outputs.ready == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
    steps:
      - uses: actions/checkout@v4

      - uses: hashicorp/setup-terraform@v3

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Clear stale Terraform lock (idempotent)
        working-directory: infra
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
        run: ./clear-stale-lock.sh

      - name: Bootstrap remote backend (idempotent)
        working-directory: infra
        run: |
          bash backend-bootstrap.sh

      - name: Terraform init
        working-directory: infra
        run: terraform init -upgrade

      - name: Import existing resources to avoid duplicates
        working-directory: infra
        run: bash import-if-exists.sh || true

      - name: Optional destroy (recreate)
        if: ${{ inputs.recreate }}
        working-directory: infra
        run: terraform destroy -auto-approve || true

      - name: Validate & Plan (detailed exit code)
        working-directory: infra
        run: |
          ./clear-stale-lock.sh
          terraform validate
          code=0
          terraform plan -detailed-exitcode \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="aws_account_id=${{ env.AWS_ACCOUNT_ID }}" \
            -var="allowed_cidrs=[\"${{ vars.ALLOWED_CIDR || '0.0.0.0/0' }}\"]" \
            -var="vertica_image=${{ vars.VERTICA_IMAGE || '957650740525.dkr.ecr.ap-south-1.amazonaws.com/vertica-ce:v1.0' }}" \
            || code=$?
          echo plan_exit=$code
          if [ "$code" = "2" ] || [ "$code" = "0" ]; then
            exit 0
          else
            exit "$code"
          fi

      - name: Apply
        working-directory: infra
        run: |
          ./clear-stale-lock.sh
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="aws_account_id=${{ env.AWS_ACCOUNT_ID }}" \
            -var="allowed_cidrs=[\"${{ vars.ALLOWED_CIDR || '0.0.0.0/0' }}\"]" \
            -var="vertica_image=${{ vars.VERTICA_IMAGE || '957650740525.dkr.ecr.ap-south-1.amazonaws.com/vertica-ce:v1.0' }}"

      - name: Fetch outputs
        id: out
        working-directory: infra
        run: |
          echo "ip=$(terraform output -raw public_ip)" >> $GITHUB_OUTPUT
          echo "dns=$(terraform output -raw public_dns)" >> $GITHUB_OUTPUT
          echo "instance_id=$(terraform output -raw instance_id)" >> $GITHUB_OUTPUT
          echo "admin_user=$(terraform output -raw additional_admin_username)" >> $GITHUB_OUTPUT
          echo "admin_pass=$(terraform output -raw additional_admin_password)" >> $GITHUB_OUTPUT
          echo "ssm_document=$(terraform output -raw ssm_smoke_test_document)" >> $GITHUB_OUTPUT
          echo "ssm_log_group=$(terraform output -raw smoke_test_log_group)" >> $GITHUB_OUTPUT

      - name: Smoke test via SSM
        env:
          INSTANCE_ID: "${{ steps.out.outputs.instance_id }}"
          ADMIN_USER: "${{ steps.out.outputs.admin_user }}"
          ADMIN_PASSWORD: "${{ steps.out.outputs.admin_pass }}"
          SSM_DOCUMENT: "${{ steps.out.outputs.ssm_document }}"
          SSM_LOG_GROUP: "${{ steps.out.outputs.ssm_log_group }}"
        run: |
          set -euo pipefail
          echo "Waiting for instance $INSTANCE_ID to pass EC2 status checks..."
          if ! aws ec2 wait instance-status-ok --instance-ids "$INSTANCE_ID"; then
            echo "Instance did not reach status-ok. Current status:"
            aws ec2 describe-instance-status --instance-ids "$INSTANCE_ID" --include-all-instances || true
            exit 1
          fi

          echo "Waiting for instance $INSTANCE_ID to register with AWS Systems Manager..."
          deadline=$((SECONDS + 900))
          ssm_entry="[]"
          while [ $SECONDS -lt $deadline ]; do
            ssm_entry=$(aws ssm describe-instance-information \
              --query "InstanceInformationList[?InstanceId=='$INSTANCE_ID']" \
              --output json)
            if [ "$ssm_entry" != "[]" ]; then
              break
            fi
            echo "  - Instance has not reported to SSM yet; waiting 10 seconds..."
            sleep 10
          done

          if [ "$ssm_entry" = "[]" ]; then
            echo "Instance failed to register with SSM before timeout. Current inventory entry (if any):"
            aws ssm describe-instance-information --query "InstanceInformationList[?InstanceId=='$INSTANCE_ID']" || true
            exit 1
          fi

          echo "Instance registration detected: $ssm_entry"

          eval "$(
            echo "$ssm_entry" | python3 scripts/parse_ssm_entry.py
          )"

          if [ "${association_status:-}" = "Failed" ]; then
            echo "[warn] SSM association status reported failure; aggregated counts: $association_counts"

            if [ -n "${SSM_DOCUMENT:-}" ]; then
              association_id=$(aws ssm list-associations \
                --association-filter-list Key=InstanceId,Value="$INSTANCE_ID" Key=Name,Value="$SSM_DOCUMENT" \
                --query 'Associations[0].AssociationId' \
                --output text || true)

              if [ -n "$association_id" ] && [ "$association_id" != "None" ]; then
                echo "[info] Gathering diagnostics for association $association_id"
                aws ssm describe-association --association-id "$association_id" || true

                executions=$(aws ssm describe-association-executions \
                  --association-id "$association_id" \
                  --max-results 5 \
                  --output json || true)
                echo "$executions"

                latest_execution_id=$(echo "$executions" | python3 scripts/extract_latest_execution_id.py)

                if [ -n "$latest_execution_id" ]; then
                  aws ssm describe-association-execution-targets \
                    --association-id "$association_id" \
                    --execution-id "$latest_execution_id" || true
                fi
              else
                echo "[warn] Unable to determine association ID for $SSM_DOCUMENT on $INSTANCE_ID"
              fi
            fi
          fi

          python - <<'PY'
          import base64
          import gzip
          import json
          import os
          import shlex
          import textwrap
          from pathlib import Path
          
          script_path = Path("scripts/vertica_smoke_test.py")
          admin_user = os.environ["ADMIN_USER"]
          admin_password = os.environ["ADMIN_PASSWORD"]
          
          encoded = base64.b64encode(gzip.compress(script_path.read_bytes())).decode("ascii")
          encoded_lines = "\n".join(textwrap.wrap(encoded, 120))
          
          decompress_command = "\n".join((
              "python3 <<'PY'",
              "import base64, gzip, pathlib",
              "DATA = '''",
              encoded_lines,
              "'''",
              "pathlib.Path('vertica_smoke_test.py').write_bytes(",
              "    gzip.decompress(base64.b64decode(DATA))",
              ")",
              "PY",
          ))
          
          env_parts = [
              f"ADMIN_USER={shlex.quote(admin_user)}",
              f"ADMIN_PASSWORD={shlex.quote(admin_password)}",
          ]
          pip_installer = "\n".join([
              "python3 - <<'PY'",
              "import subprocess",
              "import sys",
              "",
              "def install(requirement: str) -> None:",
              "    commands = [",
              "        [",
              "            sys.executable,",
              "            '-m',",
              "            'pip',",
              "            'install',",
              "            '--quiet',",
              "            '--no-input',",
              "            '--default-timeout',",
              "            '30',",
              "            '--retries',",
              "            '2',",
              "            requirement,",
              "        ],",
              "        [",
              "            sys.executable,",
              "            '-m',",
              "            'pip',",
              "            'install',",
              "            '--quiet',",
              "            '--no-input',",
              "            '--default-timeout',",
              "            '30',",
              "            '--retries',",
              "            '2',",
              "            '--break-system-packages',",
              "            requirement,",
              "        ],",
              "    ]",
              "",
              "    last_error = None",
              "    for command in commands:",
              "        print(f'[pip] Installing {requirement!r} via {command}', flush=True)",
              "        try:",
              "            subprocess.run(command, check=True, timeout=180)",
              "        except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as exc:",
              "            last_error = exc",
              "            print(f'[pip] Installation attempt failed: {exc}', flush=True)",
              "            continue",
              "        else:",
              "            print(f'[pip] Successfully installed {requirement!r}', flush=True)",
              "            break",
              "    else:",
              "        raise SystemExit(f'Failed to install {requirement}: {last_error}')",
              "",
              "install('urllib3<2')",
              "install('vertica-python==1.4.0')",
              "PY",
          ])

          commands = [
              "set -euo pipefail",
              "if ! python3 -m pip --version >/dev/null 2>&1; then python3 -m ensurepip --upgrade || (dnf install -y python3-pip); fi",
              "if command -v rpm >/dev/null 2>&1 && rpm -q python3-pip >/dev/null 2>&1; then",
              "  echo '[info] Skipping pip upgrade because python3-pip is managed by the system package manager'",
              "elif ! python3 -m pip install --quiet --upgrade pip; then",
              "  echo '[warn] Unable to upgrade pip; continuing with system-provided version'",
              "fi",
              pip_installer,
              decompress_command,
              f"{' '.join(env_parts)} python3 vertica_smoke_test.py",
          ]
          Path("ssm-commands.json").write_text(
              json.dumps({"commands": commands}, indent=2)
          )
          PY

          command_id=$(aws ssm send-command \
            --document-name AWS-RunShellScript \
            --comment "Vertica smoke test" \
            --instance-ids "$INSTANCE_ID" \
            --parameters file://ssm-commands.json \
            --cloud-watch-output-config '{"CloudWatchLogGroupName": "'$SSM_LOG_GROUP'", "CloudWatchOutputEnabled": true}' \
            --query 'Command.CommandId' \
            --output text)

          COMMAND_ID="$command_id" python - <<'PY'
          import datetime as dt
          import hashlib
          import json
          import os
          import subprocess
          import sys
          import time
          
          command_id = os.environ['COMMAND_ID']
          instance_id = os.environ['INSTANCE_ID']
          log_group = os.environ.get('SSM_LOG_GROUP', '')
          timeout_seconds = 2100
          deadline = time.monotonic() + timeout_seconds
          
          os.environ.setdefault('AWS_PAGER', '')
          
          
          def aws_cli_json(args, *, allow_failure=False, default=None, retry_on_throttle=True):
              cmd = ['aws', *args, '--output', 'json', '--no-cli-pager']
              result = subprocess.run(cmd, capture_output=True, text=True)
              if result.returncode != 0:
                  stderr = result.stderr.strip()
                  throttled = 'ThrottlingException' in stderr
                  invocation_missing = 'InvocationDoesNotExist' in stderr
                  not_found = 'ResourceNotFoundException' in stderr
                  if allow_failure and (invocation_missing or not_found or (throttled and retry_on_throttle)):
                      if throttled and retry_on_throttle:
                          time.sleep(1)
                      return default
                  raise RuntimeError(
                      f"Command {' '.join(cmd)} failed with exit code {result.returncode}: {stderr or result.stdout}"
                  )

              output = result.stdout.strip()
              if not output:
                  return default
              try:
                  return json.loads(output)
              except json.JSONDecodeError as exc:  # pragma: no cover - defensive guard for CLI output changes
                  raise RuntimeError(
                      f'Failed to decode JSON from {" ".join(cmd)}: {exc}\nRaw output: {result.stdout}'
                  ) from exc
          
          
          def log(message: str) -> None:
              timestamp = dt.datetime.now(dt.timezone.utc).isoformat()
              print(f"[{timestamp}] {message}", flush=True)
          
          
          last_status = None
          last_details = None
          last_status_emit = 0.0
          plugin_state: dict[str, tuple[str, int | None, str | None]] = {}
          log_stream_name: str | None = None
          next_token: str | None = None
          printed_events: set[tuple[int, str]] = set()
          final_invocation: dict | None = None
          
          while time.monotonic() < deadline:
              invocation = aws_cli_json(
                  ['ssm', 'get-command-invocation', '--command-id', command_id, '--instance-id', instance_id],
                  allow_failure=True,
                  default=None,
              )
          
              status = 'InProgress'
              status_details = ''
              if invocation:
                  status = invocation.get('Status') or status
                  status_details = invocation.get('StatusDetails') or ''
              else:
                  status = 'Pending'
                  status_details = 'Command invocation not yet initialised'
          
              now = time.monotonic()
              if status != last_status or status_details != last_details:
                  if status_details:
                      log(f'SSM status: {status} ({status_details})')
                  else:
                      log(f'SSM status: {status}')
                  last_status = status
                  last_details = status_details
                  last_status_emit = now
              elif now - last_status_emit >= 60.0:
                  log(f'SSM status unchanged: {status}')
                  last_status_emit = now
          
              if invocation and status in {'Failed', 'Cancelled', 'TimedOut', 'Cancelling'}:
                  print(json.dumps(invocation, indent=2), flush=True)
                  sys.exit(1)
          
              plugin_list = aws_cli_json(
                  ['ssm', 'list-command-invocations', '--command-id', command_id, '--details'],
                  allow_failure=True,
                  default={},
              )
              for inv in plugin_list.get('CommandInvocations', []):
                  if inv.get('InstanceId') != instance_id:
                      continue
                  for plugin in inv.get('CommandPlugins', []):
                      name = plugin.get('Name', '<unknown>')
                      plugin_status = plugin.get('StatusDetails') or plugin.get('Status') or ''
                      response_code = plugin.get('ResponseCode')
                      output = plugin.get('Output') or ''
                      output_hash = hashlib.sha256(output.encode('utf-8')).hexdigest() if output else None
                      digest = (plugin_status, response_code, output_hash)
                      if plugin_state.get(name) != digest:
                          plugin_state[name] = digest
                          status_line = plugin_status or 'Unknown'
                          if response_code not in (None, -1):
                              status_line = f"{status_line} (code {response_code})"
                          log(f'Plugin {name}: {status_line}')
                          trimmed_output = output.strip()
                          if trimmed_output:
                              tail_lines = trimmed_output.splitlines()[-20:]
                              for line in tail_lines:
                                  print(f'    [plugin] {line}', flush=True)
          
              if log_group:
                  if not log_stream_name:
                      streams = aws_cli_json(
                          [
                              'logs',
                              'describe-log-streams',
                              '--log-group-name',
                              log_group,
                              '--log-stream-name-prefix',
                              f'{command_id}/{instance_id}',
                          ],
                          allow_failure=True,
                          default={'logStreams': []},
                      )
                      for stream in streams.get('logStreams', []):
                          candidate = stream.get('logStreamName')
                          if candidate:
                              log_stream_name = candidate
                              log(f'Discovered CloudWatch Logs stream: {log_stream_name}')
                              break

              if log_stream_name:
                  log_events_args = [
                      'logs',
                      'get-log-events',
                      '--log-group-name',
                      log_group,
                      '--log-stream-name',
                      log_stream_name,
                  ]
                  if next_token:
                      log_events_args.extend(['--next-token', next_token])
                  else:
                      log_events_args.append('--start-from-head')

                  events_data = aws_cli_json(
                      log_events_args,
                      allow_failure=True,
                      default=None,
                  )
                  if events_data:
                      next_forward = events_data.get('nextForwardToken')
                      if next_forward:
                          next_token = next_forward
                      for event in events_data.get('events', []):
                          timestamp = event.get('timestamp')
                          message = (event.get('message') or '').rstrip('\n')
                          key = (timestamp or 0, message)
                          if key in printed_events:
                              continue
                          printed_events.add(key)
                          if timestamp is None:
                              print(f'[cw] {message}', flush=True)
                          else:
                              log_time = dt.datetime.fromtimestamp(timestamp / 1000, dt.timezone.utc).isoformat()
                              print(f'[cw][{log_time}] {message}', flush=True)
          
              if status == 'Success' and invocation:
                  final_invocation = invocation
                  break
          
              time.sleep(15)
          
          else:
              log('SSM command did not complete before timeout; fetching latest details for troubleshooting.')
              details = aws_cli_json(
                  ['ssm', 'get-command-invocation', '--command-id', command_id, '--instance-id', instance_id],
                  allow_failure=True,
                  default=None,
                  retry_on_throttle=False,
              )
              if details:
                  print(json.dumps(details, indent=2), flush=True)
              summary = aws_cli_json(
                  ['ssm', 'list-command-invocations', '--command-id', command_id, '--details'],
                  allow_failure=True,
                  default=None,
                  retry_on_throttle=False,
              )
              if summary:
                  print(json.dumps(summary, indent=2), flush=True)
              sys.exit(1)
          
          
          if final_invocation is None:
              final_invocation = aws_cli_json(
                  ['ssm', 'get-command-invocation', '--command-id', command_id, '--instance-id', instance_id],
                  allow_failure=False,
              )
          
          stdout_content = final_invocation.get('StandardOutputContent', '') or ''
          stderr_content = final_invocation.get('StandardErrorContent', '') or ''
          
          print('===== SSM command standard output =====')
          if stdout_content:
              print(stdout_content.rstrip('\n'))
          print('===== End of standard output =====')
          
          if stderr_content:
              print('===== SSM command standard error =====')
              print(stderr_content.rstrip('\n'))
              print('===== End of standard error =====')
          
          last_line = ''
          for line in stdout_content.rstrip('\n').splitlines():
              if line.strip():
                  last_line = line
          
          if 'SMOKE_TEST_SUCCESS' not in last_line:
              print('Smoke test did not report success', file=sys.stderr)
              sys.exit(1)
          PY

      - name: Job summary
        run: |
          echo "### Vertica is up" >> $GITHUB_STEP_SUMMARY
          echo "- Host: \`${{ steps.out.outputs.ip }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Port: \`5433\` User: \`${{ steps.out.outputs.admin_user }}\` Password: \`${{ steps.out.outputs.admin_pass }}\` DB: \`VMart\`" >> $GITHUB_STEP_SUMMARY
          echo "- Bootstrap user \`dbadmin\` remains available with an empty password" >> $GITHUB_STEP_SUMMARY
