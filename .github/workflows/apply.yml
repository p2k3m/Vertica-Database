name: Deploy Vertica DB (apply)

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      recreate:
        description: Destroy the existing stack before applying
        required: false
        type: boolean

concurrency:
  group: vertica-db-apply
  cancel-in-progress: false

jobs:
  preflight:
    runs-on: ubuntu-latest
    outputs:
      ready: ${{ steps.check.outputs.ready }}
    steps:
      - name: Check required AWS secrets
        id: check
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
        run: |
          set -euo pipefail
          missing=()
          for name in AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_REGION AWS_ACCOUNT_ID; do
            if [ -z "${!name:-}" ]; then
              missing+=("$name")
            fi
          done

          if [ ${#missing[@]} -eq 0 ]; then
            echo "ready=true" >> "$GITHUB_OUTPUT"
            {
              echo "### ✅ Vertica apply prerequisites"
              echo
              echo "All required AWS secrets are configured."
            } >> "$GITHUB_STEP_SUMMARY"
          else
            {
              echo "### ⚠️ Vertica apply prerequisites missing"
              echo
              echo "The deploy job was skipped because these secrets are unset:"
              for name in "${missing[@]}"; do
                echo "- \`$name\`"
              done
              echo
              echo "Set them under **Settings → Secrets and variables → Actions** to enable automatic deploys."
            } >> "$GITHUB_STEP_SUMMARY"
            echo "ready=false" >> "$GITHUB_OUTPUT"
          fi

  apply:
    needs: preflight
    if: ${{ needs.preflight.outputs.ready == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
    steps:
      - uses: actions/checkout@v4

      - uses: hashicorp/setup-terraform@v3

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Clear stale Terraform lock (idempotent)
        working-directory: infra
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
        run: ./clear-stale-lock.sh

      - name: Bootstrap remote backend (idempotent)
        working-directory: infra
        run: |
          bash backend-bootstrap.sh

      - name: Terraform init
        working-directory: infra
        run: terraform init -upgrade

      - name: Import existing resources to avoid duplicates
        working-directory: infra
        run: bash import-if-exists.sh || true

      - name: Optional destroy (recreate)
        if: ${{ inputs.recreate }}
        working-directory: infra
        run: terraform destroy -auto-approve || true

      - name: Validate & Plan (detailed exit code)
        working-directory: infra
        run: |
          ./clear-stale-lock.sh
          terraform validate
          code=0
          terraform plan -detailed-exitcode \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="aws_account_id=${{ env.AWS_ACCOUNT_ID }}" \
            -var="allowed_cidrs=[\"${{ vars.ALLOWED_CIDR || '0.0.0.0/0' }}\"]" \
            -var="vertica_image=${{ vars.VERTICA_IMAGE || '957650740525.dkr.ecr.ap-south-1.amazonaws.com/vertica-ce:v1.0' }}" \
            || code=$?
          echo plan_exit=$code
          if [ "$code" = "2" ] || [ "$code" = "0" ]; then
            exit 0
          else
            exit "$code"
          fi

      - name: Apply
        working-directory: infra
        run: |
          ./clear-stale-lock.sh
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="aws_account_id=${{ env.AWS_ACCOUNT_ID }}" \
            -var="allowed_cidrs=[\"${{ vars.ALLOWED_CIDR || '0.0.0.0/0' }}\"]" \
            -var="vertica_image=${{ vars.VERTICA_IMAGE || '957650740525.dkr.ecr.ap-south-1.amazonaws.com/vertica-ce:v1.0' }}"

      - name: Fetch outputs
        id: out
        working-directory: infra
        run: |
          echo "ip=$(terraform output -raw public_ip)" >> $GITHUB_OUTPUT
          echo "dns=$(terraform output -raw public_dns)" >> $GITHUB_OUTPUT
          echo "instance_id=$(terraform output -raw instance_id)" >> $GITHUB_OUTPUT
          echo "admin_user=$(terraform output -raw additional_admin_username)" >> $GITHUB_OUTPUT
          echo "admin_pass=$(terraform output -raw additional_admin_password)" >> $GITHUB_OUTPUT
          echo "ssm_log_group=$(terraform output -raw smoke_test_log_group)" >> $GITHUB_OUTPUT

      - name: Smoke test via SSM
        env:
          INSTANCE_ID: "${{ steps.out.outputs.instance_id }}"
          ADMIN_USER: "${{ steps.out.outputs.admin_user }}"
          ADMIN_PASSWORD: "${{ steps.out.outputs.admin_pass }}"
          SSM_LOG_GROUP: "${{ steps.out.outputs.ssm_log_group }}"
        run: |
          set -euo pipefail
          echo "Waiting for instance $INSTANCE_ID to pass EC2 status checks..."
          if ! aws ec2 wait instance-status-ok --instance-ids "$INSTANCE_ID"; then
            echo "Instance did not reach status-ok. Current status:"
            aws ec2 describe-instance-status --instance-ids "$INSTANCE_ID" --include-all-instances || true
            exit 1
          fi

          echo "Waiting for instance $INSTANCE_ID to register with AWS Systems Manager..."
          deadline=$((SECONDS + 900))
          ssm_entry="[]"
          while [ $SECONDS -lt $deadline ]; do
            ssm_entry=$(aws ssm describe-instance-information \
              --query "InstanceInformationList[?InstanceId=='$INSTANCE_ID']" \
              --output json)
            if [ "$ssm_entry" != "[]" ]; then
              break
            fi
            echo "  - Instance has not reported to SSM yet; waiting 10 seconds..."
            sleep 10
          done

          if [ "$ssm_entry" = "[]" ]; then
            echo "Instance failed to register with SSM before timeout. Current inventory entry (if any):"
            aws ssm describe-instance-information --query "InstanceInformationList[?InstanceId=='$INSTANCE_ID']" || true
            exit 1
          fi

          echo "Instance registration detected: $ssm_entry"

          python - <<'PY'
          import base64
          import gzip
          import json
          import os
          import shlex
          import textwrap
          from pathlib import Path

          script_path = Path("scripts/vertica_smoke_test.py")
          admin_user = os.environ["ADMIN_USER"]
          admin_password = os.environ["ADMIN_PASSWORD"]

          encoded = base64.b64encode(gzip.compress(script_path.read_bytes())).decode("ascii")
          encoded_lines = "\n".join(textwrap.wrap(encoded, 120))

          decompress_command = "\n".join((
              "python3 <<'PY'",
              "import base64, gzip, pathlib",
              "DATA = '''",
              encoded_lines,
              "'''",
              "pathlib.Path('vertica_smoke_test.py').write_bytes(",
              "    gzip.decompress(base64.b64decode(DATA))",
              ")",
              "PY",
          ))

          env_parts = [
              f"ADMIN_USER={shlex.quote(admin_user)}",
              f"ADMIN_PASSWORD={shlex.quote(admin_password)}",
          ]
          commands = [
              "set -euo pipefail",
              "if ! python3 -m pip --version >/dev/null 2>&1; then python3 -m ensurepip --upgrade || (dnf install -y python3-pip); fi",
              "if ! python3 -m pip install --quiet --upgrade pip; then echo '[warn] Unable to upgrade pip; continuing with system-provided version'; fi",
              "python3 -m pip install --quiet 'urllib3<2'",
              "python3 -m pip install --quiet vertica-python",
              decompress_command,
              f"{' '.join(env_parts)} python3 vertica_smoke_test.py",
          ]
          Path("ssm-commands.json").write_text(
              json.dumps({"commands": commands}, indent=2)
          )
          PY

          command_id=$(aws ssm send-command \
            --document-name AWS-RunShellScript \
            --comment "Vertica smoke test" \
            --instance-ids "$INSTANCE_ID" \
            --parameters file://ssm-commands.json \
            --cloud-watch-output-config '{"CloudWatchLogGroupName": "'$SSM_LOG_GROUP'", "CloudWatchOutputEnabled": true}' \
            --query 'Command.CommandId' \
            --output text)

          status="InProgress"
          deadline=$((SECONDS + 2100))
          last_status=""
          last_details=""
          while [ $SECONDS -lt $deadline ]; do
            status=$(aws ssm get-command-invocation \
              --command-id "$command_id" \
              --instance-id "$INSTANCE_ID" \
              --query 'Status' \
              --output text \
              2>/dev/null || echo "InProgress")
            status=${status:-InProgress}
            status_details=$(aws ssm get-command-invocation \
              --command-id "$command_id" \
              --instance-id "$INSTANCE_ID" \
              --query 'StatusDetails' \
              --output text \
              2>/dev/null || echo "")
            status_details=${status_details:-}

            if [ "$status" != "$last_status" ] || [ "$status_details" != "$last_details" ]; then
              case "$status" in
                InProgress|Pending|Delayed)
                  if [ -n "$status_details" ]; then
                    echo "  - SSM command still running (status: $status, details: $status_details)"
                  else
                    echo "  - SSM command still running (status: $status)"
                  fi
                  ;;
              esac
              last_status="$status"
              last_details="$status_details"
            fi

            case "$status" in
              Success)
                break
                ;;
              Failed|Cancelled|TimedOut|Cancelling)
                aws ssm get-command-invocation \
                  --command-id "$command_id" \
                  --instance-id "$INSTANCE_ID"
                exit 1
                ;;
            esac

            sleep 15
          done

          if [ "$status" != "Success" ]; then
            echo "SSM command did not complete before timeout (status: $status)."
            aws ssm get-command-invocation \
              --command-id "$command_id" \
              --instance-id "$INSTANCE_ID" || true
            aws ssm list-command-invocations \
              --command-id "$command_id" \
              --details || true
            exit 1
          fi

          output=$(aws ssm get-command-invocation \
            --command-id "$command_id" \
            --instance-id "$INSTANCE_ID" \
            --query 'StandardOutputContent' \
            --output text)

          stderr_output=$(aws ssm get-command-invocation \
            --command-id "$command_id" \
            --instance-id "$INSTANCE_ID" \
            --query 'StandardErrorContent' \
            --output text)

          echo "===== SSM command standard output ====="
          printf '%s\n' "$output"
          echo "===== End of standard output ====="

          if [ -n "$stderr_output" ]; then
            echo "===== SSM command standard error ====="
            printf '%s\n' "$stderr_output"
            echo "===== End of standard error ====="
          fi

          if ! printf '%s\n' "$output" | tail -n 1 | grep -q 'SMOKE_TEST_SUCCESS'; then
            echo "Smoke test did not report success" >&2
            exit 1
          fi

      - name: Job summary
        run: |
          echo "### Vertica is up" >> $GITHUB_STEP_SUMMARY
          echo "- Host: \`${{ steps.out.outputs.ip }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Port: \`5433\` User: \`${{ steps.out.outputs.admin_user }}\` Password: \`${{ steps.out.outputs.admin_pass }}\` DB: \`VMart\`" >> $GITHUB_STEP_SUMMARY
          echo "- Bootstrap user \`dbadmin\` remains available with an empty password" >> $GITHUB_STEP_SUMMARY
